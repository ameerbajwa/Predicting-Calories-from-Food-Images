{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'calorie_ranges/calorie_ranges_train/'\n",
    "validation_data_dir = 'calorie_ranges/calorie_ranges_validation/'\n",
    "nb_train_samples = 8438\n",
    "nb_validation_samples = 1000\n",
    "epochs = 60\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    im = cv2.resize(cv2.imread(image_path), (224,224)).astype(np.float32)\n",
    "\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synset = pd.read_csv('synset_words.txt', skipinitialspace=True, names = ['synset', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.T[:50,:50,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array([np.array([img.T[:,:,:,0]])]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = prepare_image('burger.jpg')\n",
    "out = new_model.predict(np.array([img.T[:,:,:,0]]))\n",
    "y_pred = np.argmax(out)\n",
    "\n",
    "print (out)\n",
    "\n",
    "categorical_labels = to_categorical(out, num_classes=None)\n",
    "print (categorical_labels)\n",
    "\n",
    "print (y_pred)\n",
    "# print (synset.loc[y_pred].synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freeze conv layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_layer = model.output\n",
    "\n",
    "x = Flatten()(last_layer)\n",
    "# x = Dropout(0.4)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(75, activation='softmax')(x)\n",
    "\n",
    "new_model = Model(model.input, predictions)\n",
    "new_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"first1.food.weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8434 images belonging to 5 classes.\n",
      "Found 1008 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# train and valdiation generator and then model.fit_generator\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine-tune the model\n",
    "new_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "# new_model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running the new model with the saved best weights from the first training model to get better val accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model.save('first30_epochs_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = load_model('first30_epochs_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath2 = \"second2.food.weights.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list2 = [checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = load_model('75epochs_75categories_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath3 = \"third.food.weights.hdf5\"\n",
    "checkpoint3 = ModelCheckpoint(filepath3, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list3 = [checkpoint3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.save('75epochs_75categories_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classweights = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classweights[0] = float(1)\n",
    "classweights[1] = float(3984/2509)\n",
    "classweights[2] = float(3984/775)\n",
    "classweights[3] = float(3984/457)\n",
    "classweights[4] = float(3984/711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = load_model('75epochs_75categories_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_layer = final_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_layer = final_model.layers[-1].output\n",
    "# final_model.get_layer(name='dense_2').name = 'dense_3'\n",
    "better_predictions = Dense(5, activation='softmax')(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_final_model = Model(final_model.input, better_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath4 = \"food.weights.hdf5\"\n",
    "checkpoint4 = ModelCheckpoint(filepath4, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list4 = [checkpoint4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_final_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list4,\n",
    "        class_weight = classweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_final_model.save('15epochs_calorie_classifying_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('15epochs_calorie_classifying_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath4 = \"75epochs_calorie_classifying_food.weights.hdf5\"\n",
    "checkpoint4 = ModelCheckpoint(filepath4, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list4 = [checkpoint4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py:874: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842/843 [============================>.] - ETA: 0s - loss: 3.5752 - acc: 0.4072Epoch 00000: val_acc improved from -inf to 0.32400, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 387s - loss: 3.5732 - acc: 0.4075 - val_loss: 1.5123 - val_acc: 0.3240\n",
      "Epoch 2/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.5511 - acc: 0.4233Epoch 00001: val_acc improved from 0.32400 to 0.33667, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 387s - loss: 3.5508 - acc: 0.4231 - val_loss: 1.5073 - val_acc: 0.3367\n",
      "Epoch 3/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.5422 - acc: 0.4157Epoch 00002: val_acc improved from 0.33667 to 0.34168, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 381s - loss: 3.5456 - acc: 0.4156 - val_loss: 1.4943 - val_acc: 0.3417\n",
      "Epoch 4/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.5340 - acc: 0.4212Epoch 00003: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.5349 - acc: 0.4211 - val_loss: 1.5123 - val_acc: 0.3206\n",
      "Epoch 5/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.5272 - acc: 0.4277Epoch 00004: val_acc improved from 0.34168 to 0.34369, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 382s - loss: 3.5258 - acc: 0.4281 - val_loss: 1.4905 - val_acc: 0.3437\n",
      "Epoch 6/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.5144 - acc: 0.4293Epoch 00005: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.5131 - acc: 0.4292 - val_loss: 1.5023 - val_acc: 0.3226\n",
      "Epoch 7/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.5045 - acc: 0.4252Epoch 00006: val_acc improved from 0.34369 to 0.36874, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 381s - loss: 3.5050 - acc: 0.4254 - val_loss: 1.4748 - val_acc: 0.3687\n",
      "Epoch 8/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4899 - acc: 0.4339Epoch 00007: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4887 - acc: 0.4337 - val_loss: 1.4765 - val_acc: 0.3477\n",
      "Epoch 9/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4700 - acc: 0.4395Epoch 00008: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4682 - acc: 0.4396 - val_loss: 1.4875 - val_acc: 0.3427\n",
      "Epoch 10/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4846 - acc: 0.4378Epoch 00009: val_acc improved from 0.36874 to 0.37074, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 381s - loss: 3.4839 - acc: 0.4380 - val_loss: 1.4705 - val_acc: 0.3707\n",
      "Epoch 11/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4648 - acc: 0.4362Epoch 00010: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4658 - acc: 0.4362 - val_loss: 1.4866 - val_acc: 0.3527\n",
      "Epoch 12/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4396 - acc: 0.4414Epoch 00011: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4384 - acc: 0.4414 - val_loss: 1.4846 - val_acc: 0.3647\n",
      "Epoch 13/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4504 - acc: 0.4391Epoch 00012: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4525 - acc: 0.4391 - val_loss: 1.4858 - val_acc: 0.3397\n",
      "Epoch 14/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4345 - acc: 0.4474Epoch 00013: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4347 - acc: 0.4475 - val_loss: 1.4692 - val_acc: 0.3587\n",
      "Epoch 15/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4301 - acc: 0.4493Epoch 00014: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4298 - acc: 0.4495 - val_loss: 1.4862 - val_acc: 0.3547\n",
      "Epoch 16/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4059 - acc: 0.4473Epoch 00015: val_acc improved from 0.37074 to 0.38577, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 381s - loss: 3.4057 - acc: 0.4474 - val_loss: 1.4369 - val_acc: 0.3858\n",
      "Epoch 17/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4190 - acc: 0.4403Epoch 00016: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.4198 - acc: 0.4404 - val_loss: 1.4700 - val_acc: 0.3747\n",
      "Epoch 18/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3971 - acc: 0.4472Epoch 00017: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3994 - acc: 0.4469 - val_loss: 1.4640 - val_acc: 0.3557\n",
      "Epoch 19/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4064 - acc: 0.4549Epoch 00018: val_acc improved from 0.38577 to 0.38778, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 381s - loss: 3.4074 - acc: 0.4549 - val_loss: 1.4389 - val_acc: 0.3878\n",
      "Epoch 20/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3847 - acc: 0.4497Epoch 00019: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3844 - acc: 0.4499 - val_loss: 1.4500 - val_acc: 0.3707\n",
      "Epoch 21/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3908 - acc: 0.4471Epoch 00020: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3899 - acc: 0.4473 - val_loss: 1.4620 - val_acc: 0.3798\n",
      "Epoch 22/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.4001 - acc: 0.4434Epoch 00021: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3982 - acc: 0.4435 - val_loss: 1.4430 - val_acc: 0.3697\n",
      "Epoch 23/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3904 - acc: 0.4474Epoch 00022: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3904 - acc: 0.4476 - val_loss: 1.4634 - val_acc: 0.3577\n",
      "Epoch 24/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3623 - acc: 0.4506Epoch 00023: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3610 - acc: 0.4508 - val_loss: 1.4665 - val_acc: 0.3677\n",
      "Epoch 25/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3576 - acc: 0.4483Epoch 00024: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3555 - acc: 0.4485 - val_loss: 1.4351 - val_acc: 0.3717\n",
      "Epoch 26/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3398 - acc: 0.4548Epoch 00025: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3409 - acc: 0.4550 - val_loss: 1.5062 - val_acc: 0.3387\n",
      "Epoch 27/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3588 - acc: 0.4545Epoch 00026: val_acc improved from 0.38778 to 0.40281, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 382s - loss: 3.3579 - acc: 0.4547 - val_loss: 1.4142 - val_acc: 0.4028\n",
      "Epoch 28/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3398 - acc: 0.4568Epoch 00027: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3391 - acc: 0.4569 - val_loss: 1.4512 - val_acc: 0.3647\n",
      "Epoch 29/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3389 - acc: 0.4524Epoch 00028: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3384 - acc: 0.4521 - val_loss: 1.4653 - val_acc: 0.3387\n",
      "Epoch 30/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3396 - acc: 0.4549Epoch 00029: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3391 - acc: 0.4549 - val_loss: 1.4619 - val_acc: 0.3878\n",
      "Epoch 31/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3210 - acc: 0.4567Epoch 00030: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3221 - acc: 0.4566 - val_loss: 1.4308 - val_acc: 0.3737\n",
      "Epoch 32/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3102 - acc: 0.4602Epoch 00031: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3117 - acc: 0.4602 - val_loss: 1.4302 - val_acc: 0.3818\n",
      "Epoch 33/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3172 - acc: 0.4632Epoch 00032: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3167 - acc: 0.4631 - val_loss: 1.4256 - val_acc: 0.3788\n",
      "Epoch 34/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3111 - acc: 0.4588Epoch 00033: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3093 - acc: 0.4587 - val_loss: 1.4334 - val_acc: 0.3808\n",
      "Epoch 35/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3005 - acc: 0.4653Epoch 00034: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3010 - acc: 0.4651 - val_loss: 1.4579 - val_acc: 0.3577\n",
      "Epoch 36/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.3004 - acc: 0.4508Epoch 00035: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.3002 - acc: 0.4509 - val_loss: 1.4301 - val_acc: 0.3788\n",
      "Epoch 37/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2689 - acc: 0.4686Epoch 00036: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2690 - acc: 0.4687 - val_loss: 1.4281 - val_acc: 0.3737\n",
      "Epoch 38/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2841 - acc: 0.4567Epoch 00037: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2841 - acc: 0.4566 - val_loss: 1.4252 - val_acc: 0.3898\n",
      "Epoch 39/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2738 - acc: 0.4628Epoch 00038: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2740 - acc: 0.4630 - val_loss: 1.4242 - val_acc: 0.3768\n",
      "Epoch 40/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2588 - acc: 0.4658Epoch 00039: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2599 - acc: 0.4658 - val_loss: 1.4228 - val_acc: 0.3808\n",
      "Epoch 41/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2558 - acc: 0.4621Epoch 00040: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2562 - acc: 0.4617 - val_loss: 1.4332 - val_acc: 0.4028\n",
      "Epoch 42/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2681 - acc: 0.4621Epoch 00041: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2697 - acc: 0.4623 - val_loss: 1.4403 - val_acc: 0.3768\n",
      "Epoch 43/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2271 - acc: 0.4698Epoch 00042: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2267 - acc: 0.4698 - val_loss: 1.4345 - val_acc: 0.3898\n",
      "Epoch 44/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2722 - acc: 0.4593Epoch 00043: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2719 - acc: 0.4594 - val_loss: 1.4277 - val_acc: 0.3898\n",
      "Epoch 45/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2742 - acc: 0.4571Epoch 00044: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2731 - acc: 0.4574 - val_loss: 1.4269 - val_acc: 0.3727\n",
      "Epoch 46/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2281 - acc: 0.4679Epoch 00045: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2272 - acc: 0.4682 - val_loss: 1.4061 - val_acc: 0.3868\n",
      "Epoch 47/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2121 - acc: 0.4629Epoch 00046: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2119 - acc: 0.4629 - val_loss: 1.4035 - val_acc: 0.3998\n",
      "Epoch 48/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2432 - acc: 0.4602Epoch 00047: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2454 - acc: 0.4600 - val_loss: 1.4084 - val_acc: 0.3978\n",
      "Epoch 49/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2379 - acc: 0.4657Epoch 00048: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2372 - acc: 0.4654 - val_loss: 1.4231 - val_acc: 0.3597\n",
      "Epoch 50/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1981 - acc: 0.4708Epoch 00049: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1993 - acc: 0.4705 - val_loss: 1.4482 - val_acc: 0.3577\n",
      "Epoch 51/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2219 - acc: 0.4497Epoch 00050: val_acc improved from 0.40281 to 0.40481, saving model to 75epochs_calorie_classifying_food.weights.hdf5\n",
      "843/843 [==============================] - 382s - loss: 3.2202 - acc: 0.4501 - val_loss: 1.3907 - val_acc: 0.4048\n",
      "Epoch 52/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1963 - acc: 0.4485Epoch 00051: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1960 - acc: 0.4485 - val_loss: 1.4116 - val_acc: 0.3818\n",
      "Epoch 53/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2368 - acc: 0.4401Epoch 00052: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2372 - acc: 0.4398 - val_loss: 1.3991 - val_acc: 0.3898\n",
      "Epoch 54/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2009 - acc: 0.4483Epoch 00053: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2000 - acc: 0.4483 - val_loss: 1.3988 - val_acc: 0.3697\n",
      "Epoch 55/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.2033 - acc: 0.4545Epoch 00054: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.2012 - acc: 0.4546 - val_loss: 1.3969 - val_acc: 0.3988\n",
      "Epoch 56/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1840 - acc: 0.4524Epoch 00055: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1832 - acc: 0.4525 - val_loss: 1.4039 - val_acc: 0.3687\n",
      "Epoch 57/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1965 - acc: 0.4516Epoch 00056: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1976 - acc: 0.4514 - val_loss: 1.3961 - val_acc: 0.3908\n",
      "Epoch 58/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1694 - acc: 0.4545Epoch 00057: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1685 - acc: 0.4547 - val_loss: 1.3784 - val_acc: 0.3948\n",
      "Epoch 59/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1802 - acc: 0.4474Epoch 00058: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1797 - acc: 0.4474 - val_loss: 1.3744 - val_acc: 0.4028\n",
      "Epoch 60/60\n",
      "842/843 [============================>.] - ETA: 0s - loss: 3.1567 - acc: 0.4524Epoch 00059: val_acc did not improve\n",
      "843/843 [==============================] - 381s - loss: 3.1563 - acc: 0.4524 - val_loss: 1.3933 - val_acc: 0.3938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02a2390da0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list4,\n",
    "        class_weight = classweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('60epochs_calorie_classifying_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running restaurant images to get the 256 feature vectors to then do Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_practice = load_model('first30_epochs_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_practice.layers.pop()\n",
    "model_practice.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_features= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_image_names = [f for f in listdir('food_images/dennyspics/') if isfile(join('food_images/dennyspics/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image_name in list_image_names:\n",
    "    \n",
    "    file_path = 'food_images/dennyspics/'+image_name\n",
    "    \n",
    "    img = image.load_img(file_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0\n",
    "    \n",
    "    out = model_practice.predict(x)\n",
    "    list_of_features.append(out[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
